\chapter{Related work}\label{chap:related-work}
Generally such models can be divided into two types: deterministic and statistical. The following sections provide examples of predictive systems proposed in the literature with the emphasis on the statistical ones, which this this study is focused on. A summary of the results reported in the related studies can be found in table \ref{tab:related-work-results}. Tables \ref{tab:related-work-air-quality-variables} - \ref{tab:related-work-other-variables} contain information about the input variables considered in each cited article.

\section{Deterministic models}
Deterministic models are based on mathematical relationships representing the processes influencing the concentrations of pollutants in the atmosphere. These process can be summarised as: emission (production of pollutants), chemical reactions - different compounds can interact with each other creating new ones, transport - pollutants change their location due to wind and, to a lesser extent, diffusion, deposition - molecules fall on the surface of Earth due to gravity, either by themselves (dry deposition) or with rain (wet deposition) \cite{JACOBI1999}.
\\\\
Deterministic models can be generally divided into two groups. The first one are Eulerian models - they assume that the area, the forecast is made for, is divided into a grid of boxes \cite{MCMURRY2004}. Creation of pollutant molecules, their deposition and interactions between them are handled individually inside each box. Since Eulerian models have fixed frames of reference, they treat transport of pollutant masses as an exchange between neighbouring boxes. Movement of particles inside a single box may be ignored (depending on a specific model) - pollutants are assumed to be spread uniformly throughout the box. The rate of change of pollutant mass inside a box can generally be expressed as equation \ref{eq:related-work-deterministic-eulerian} \cite{JACOBI1999}.

\begin{equation} \label{eq:related-work-deterministic-eulerian}
    \frac{dm}{dt} = F_{in} + E + P - F_{out} - L - D
\end{equation}
Symbols used in equation \ref{eq:related-work-deterministic-eulerian} have the following meaning: $F_{in}$ is the influx of pollutant molecules into the box, $F_{out}$ is the amount that has escaped the box, $E$ is the emission inside the box, $P$ and $L$ are the amounts of a pollutant that were created or reduced through chemical reactions and $D$ is the amount being deposed.
\\\\
Another group of models is described as Lagrangian. They differ from Eulerian models in the fact that they use mobile frames of reference corresponding to each cloud (\textit{puffs}) made of pollutant molecules \cite{MCMURRY2004}. Changes of pollutant concentrations $c$ may be described in such model with equation \ref{eq:related-work-deterministic-lagrangian} (\cite{JACOBI1999}).
\begin{equation} \label{eq:related-work-deterministic-lagrangian}
    \frac{dc}{dt} = E + P - L - D
\end{equation}
It is similar to equation \ref{eq:related-work-deterministic-eulerian}, however there are no transport terms ($F_{in}$, $F_{out}$) because movement of pollutant masses is handled by calculating their trajectories.
\\
Both of the equations presented in this section - \ref{eq:related-work-deterministic-eulerian} and \ref{eq:related-work-deterministic-lagrangian} - are in fact considerably simplified forms of the continuity equation, which describes the process of pollutant mass transfer taking place in the atmosphere. The $F$, $E$, $P$, $L$, $D$ symbols are umbrella terms which in real world forecasting systems may include many factors, e.g.: friction between air masses and the surface of Earth, air turbulence, influence of mixing height, Coriolis effect, collisions with terrain obstacles, type of land usage \cite{JACOBI1999} \cite{MCMURRY2004}. Additionally, performing a simulation actually requires solving a system of differential equations. Coupling of those equations may be caused for example by modelling multiple interconnected domains (Eulerian box models) or taking into account chemical species that react with each other. Such complexity of a model directly translates to high hardware requirements.
\\\\
An example of a deterministic system (Lagrangian) is the \textit{Forecasting of Air Pollution Propagation System} (further referred to as FAPPS) \cite{HAJTO2012FAPPS} operated by the branch office of the Polish Institute of Meteorology and Water Management (\textit{IMGW}) located in Krakow. The system is comprised of 4 sub-models, making up a data pipeline - output of one model is passed as input to the next one:
\begin{itemize}
    \item ALADIN - a numerical weather forecast model,
    \item MM5 - a limited-area atmospheric circulation model,
    \item CALMET - a weather preprocessor responsible for calculating the effects of the local topography on mixing and movement of air masses,
    \item CALPUFF - atmospheric dispersion model calculating future pollutant concentrations.
\end{itemize}
The system is used for forecasting hourly and daily (24 hours) concentrations of four pollutants: $PM2.5$, $PM10$, $NO_2$, $SO_2$ for the next two days over the area of the Lesser Poland region (including Krakow).
\\\\
When it comes to prediction goodness, Godłowska et al. performed an evaluation of the system for the Silesian and Lesser Poland regions during two periods with higher than usual emmissions: between $23^{rd}$ and $29^{th}$ of August, 2009 and between $21^{st}$ and $29^{th}$ of January, 2010, accordnigly \cite{GODLOWSKA2011}. Three pollutants were taken into account: $PM10$, $SO_2$ and $NO_x$ ($NO + NO_2$). Predictions were made up to 27 hours in advance. The authors found that the model managed to predict the winter episode of increased $PM10$ and $SO_2$ concentrations, however for $PM10$ and $NO_x$ pollution levels tended to be underestimated and for $SO_2$ - overestimated. It is hard to give specific error values since the results were presented in the form of line plots. During summer they varied from a few to about 75$\mu g/m^3$ for $PM10$, 160$\mu g/m^3$ for $SO_2$ and 230$\mu g/m^3$ for $NO_x$. For the winter period errors reached maximum values of about 700$\mu g/m^3$ for $PM10$, 1000$\mu g/m^3$ for $SO_2$ and 780$\mu g/m^3$ for $NO_x$.
\\\\
Multiple studies similar to \cite{GODLOWSKA2011} have been performed for other cities in order to evaluate the prediction accuracy of similar deterministic models. For example Finardi et al. \cite{FINARDI2008} developed a system for predicting the  concentrations of $PM10$, $NO_2$ and $O_3$ up to 72 hours in advance in Torino, Italy (later adapted also to the city of Novara). It was verified using data from two periods: 19 - 21 of July, 1999 and 13 - 15 of January 2003. In the case of the summer episode the error terms varied between a few $\mu g/m^3$ and about 35 $\mu g/m^3$ for $NO_2$ and 90 $\mu g/m^3$ for $O_3$ (again, the errors are approximated based on plots since no explicit values were reported). The winter scenario was concerned with $PM10$ and $NO_2$ levels. The predicted values turned out to be underestimated. The authors decided not to include plots depicting the results.
\\\\
Another study was performed by Nttawut et al. with the goal of comparing performance of two models: AERMOD and CALPUFF (which the FAPPS system is based on). The prediction task concerned mean hourly concentrations of $NO_2$ and $SO_2$ in the Maptaphut industrial area (Thailand) \cite{NATTAWUT2015}. The authors used a data set comprised of air quality measurements taken in the 2012-2013 period in 10 monitoring stations. Meteorological observations were simulated, using the MM5 model. Both AERMOD and CALPUFF models were found to provide rather satisfactory accuracy with the former one generally performing better. The AERMOD model was characterised by the following statistics: RMSE: 3.72 – 40.46 $\mu g/m^3$ ($NO_2$) and 13.67 – 55.66 $\mu g/m^3$ ($SO_2$), $R^2$: 0.89 – 0.99 ($NO_2$) and 0.89 – 0.99 ($SO_2$).
\\\\
The CALPUFF models was also applied to data gathered in another Polish city - Warsaw - by Holnicki et al. \cite{HOLNICKI2016393}. The goal of the study was to test the accuracy of predicting mean concentrations of: $NO_x$, $SO_2$, $PM2.5$, $PM10$, $CO$ and $C_6H_6$ for two time scales: annual and hourly. In the first case the goodness of fit was reported  using the FAC2 index, which is the ratio of the measured concentrations to the observed ones. For all pollutants except $NO_x$ the model met the standard of $0.5 \leq FAC2 \leq 2$ assumed by the authors. Verification of hourly forecasting capability was performed on the data gathered during January 2012. The results were found to be reather satisfactory for $NO_x$ and, to lesser extent, for $PM2.5$ and $PM10$. In the case of $SO_2$, performance was reported to be poor. It is hard to cite specific values of error term because, once again, they were presented in the form of plots. Additionally the highest predicted values do not fit into the chart windows. On the other hand in most cases the errors seem to not exceed the level of 200$\mu g/m^3$ for $NO_x$, 30$\mu g/m^3$ for $PM2.5$ and $PM10$ and 20$\mu g/m^3$ for $SO_2$.

\section{Statistical models}
Another group of models, which this study is primarily concerned with, are statistical models. They differ from the deterministic ones in the fact, they are trained in order to capture relationships between factors included in the data set, rather than being provided with explicit mathematical formulas. The following sections present results of application of different types of such models to the problem of air quality prediction reported by other researchers.

\subsection{Regression models}
One of the commonly used statistical methods is multivariate linear regression. It is based on a relatively simple principle - it assumes that the predicted variable is linearly dependent on multiple explanatory variables (equation \ref{eq:models-regression}).

\begin{equation}\label{eq:models-regression}
    y_i = {\beta}_0 + \sum_{j = 1}^{p} {{\beta}_j x_{ij}} + {\epsilon}_i
\end{equation}

Meaning of the symbols used in the equation is as follows: $y_i$ is the $i^{th}$ value of the response variable, $x_ij$ is the $i^{th}$ value of the $j^{th}$ explanatory variable with ${\beta}_i$ being the corresponding weight, ${\beta}_0$ is the intercept which can be interpreted as the mean value of the response variable when all of the explanatory variables are equal to 0, $p$ is the number of dependent variables, ${epsilon}_i$ is the error factor expressing the difference between the actual and predicted values of the response variable. 
The goal of regression is to find such values of the parameters $\beta$ that the the sum of squared errors is minimised (equation \ref{eq:models-regression-sse}, symbol $\hat{y_i}$ is the $i^{th}$ actual value of the response variable).
\begin{equation}\label{eq:models-regression-sse}
    SSE = \sum_{i=1}^{n} {(y_i -  \hat{y_i})^2} = \sum_{i = 1}^{n} {{\epsilon}_i}^2
\end{equation}

Some of the advantages of linear regression are the facts that it is computationally inexpensive and widely available in statistical software packages. However, its applicability is limited by the assumptions that must be met by the data set:
\begin{itemize}
    \item linear relationship between the response variable and predictors,
    \item independence of the response variable values,
    \item normal distribution of the errors with mean equal to zero,
    \item lack of perfect collinearity between the predictors,
    \item lack of correlation between the predictors and error terms,
    \item constant variance of errors all predictor combinations     (\textit{homoscedascicity}),
    \item lack of autocorrelation between the error terms.
\end{itemize}
A more detailed description of the mentioned assumptions can be found in \cite{HOFFMAN2008}. Regardless, it is commonly used as a frame of reference, while testing more complex models (examples include: \cite{GARDNER1999709}, \cite{AGIRREBASURKO2006430}, \cite{VLACHOGIANNI20111559}, \cite{PEREZ20024555}, \cite{BIANCOFIORE2017652}, \cite{DIAZROBLES20088331}, \cite{CATALANO201669}). Additionally, some researchers have experimented with combining the standard MLR method with other techniques. For example \cite{Paschalidou2009} developed a MLR model for the purpose of finding relationships between concentrations of tropospheric ozone and several meteorological and air quality factors in two sites located in Athens, Greece. The authors reported that applying Principal Component Analysis before performing stepwise regression allowed them to reduce the multicollinearity between predictors and improve the accuracy of the model.
\\\\
Linear regression is not the only kind of regression that has been applied to prediction of air quality. \cite{COBOURN20103015} created a nonlinear regression model in order to use it with an automated $PM2.5$ forecasting system in Louisville, Kentucky (USA). The nonlinear part of the regression equation is comprised of the product of a quadratic polynomial of the maximum daily temperature and the value of exponential function of mean wind speed between 10 a.m. and 4 p.m. The model makes use of a persistence factor - previous day peak $PM2.5$ concentration - and 24-hour $PM2.5$ backward trajectory concentrations. The author points out that incorporating these two factors in the model increased the accuracy of prediction (Mean Absolute Error: 4.4$\mu g/m^3$ compared to 6.0 $\mu g/m^3$ for the base model).
\\\\
Another example is the nonlinear model presented in \cite{Sotoudeheian2014} which is meant to represent the relationship between the natural logarithm of the ground level $PM10$ concentrations and weather factors such as temperature, relative humidity, wind speed, wind direction, planetary boundary layer height as well as the aerosol optical depth (AOL) gathered from The Moderate Resolution Imaging Spectroradiometer and Multiangle Imaging SpectroRadiometer mounted on the Terra and Aqua satellites. The $PM10$ concentrations were averaged over the periods 10 a.m. - 11 a.m. and 12 a.m. - 1 p.m., when the satellite data is recorded. The researchers concluded that the nonlinear model outperformed the linear ones created for comparison. They also investigated the possibility of creating a single model for the whole data set coming from 4 stations located in Teheran, however the accuracy of the tested models turned out to by unsatisfactory.
\\\\
\cite{WESTERLUND201422} proposed a method of combining multiple linear regression models - distributed lag models and autoregressive distributed lag models - for the purpose of predicting daily means of several air pollutants ($PM10$, $CO$, $NO_x$, $NO_2$, $SO_2$, $O_3$) in Bogota, the capital of Colombia. Models were created with four different subsets of input variables including air quality data, weather factors and temporal variables. Predictions made by single models were combined with weights based on several criteria e.g. Bayesian Information Criterion and Smoothed Akaike Information Criterion. The authors reported that the resulting model outperformed individual linear models and a neural network. However, the measure used in the article, Relative Mean Square Forecast Error, which is the MSFE of the model divided by the MSFE of the best model for the specific pollutant, does not tell, what is the actual (non-relative) error of the considered model.
\\\\
\cite{GARCIANIETO201450} developed a model based on the multivariate adaptive regression splines  method (MARS) in order to forecast the mean monthly concentrations of several pollutants - $PM10$, $CO$, $NO_x$, $SO_2$ - in the city of Gijón, Spain. MARS is an automated method of fitting piecewise polynomial basis functions to the input data. It is nonparametric - it does not require specifying the degree of splines or the number of spline knots. The prediction was based only on the historic concentrations of the pollutants. Goodness of fit was reported using the coefficient of determination $R^2$, which ranged from 0.77 for $PM10$ to 0.95 for $NO_2$. 


\subsection{Neural networks}
Statistical models are not limited to the regression-based ones. An alternative group is comprised of artificial neural networks. In contrast to regression models, they are trained the mappings between the input vectors and output values using iterative algorithms like the back-propagation algorithm. Neural networks have been applied to the problem of air quality forecast multiple times, at least since the 1990s and are still popular among researchers.
\\\\
\cite{GARDNER1999709} were one of the first researchers who used neural networks - specifically a multilayer perceptrons (MLPs) - to predict hourly $NO_x (NO + NO_2)$ concentrations 1 hour and 24 hours in advance. Tests performed by the authors suggested that neural networks might perform reasonably well - squared coefficient of correlation between the predicted and actual concentrations in the case of the best model was equal to 0.51.
\\\\
\cite{PEREZ20024555} used a neural network for forecasting the maximum of  24-hour moving average of $PM10$ concentrations in Santiago, Chile, 30 hours in advance. The predictions were made based on the previous $PM10$ concentrations and a few weather factors: temperature, humidity and wind speed. The authors concluded that the ANN performed slightly better than a linear model. The reported relative percentage errors were of the order of 20\%.
\\\\
\cite{KUKKONEN2003} compared performance of prediction of $PM10$ and $NO_2$ concentrations in Helsinki, using five neural networks with different Gaussian noises, a linear model and a deterministic model. Input data used in the study included concentrations of pollutants, multiple weather factors and temporal variables. In the case of the deterministic model information about the traffic flow was also utilised. The authors reported that the NNs outperformed the remaining models.
\\\\
\cite{CORANI2005513} compared three methods for forecasting the maximum  8-hours moving average of ozone concentrations: a feed-forward neural network, a pruned neural network (a network with a reduced number of connections between neurons) and a lazy learning model. There were no significant differences in the accuracy of prediction. Having said that, the lazy loading model was reported to give the best average goodness of prediction, while the pruned neural network proved to be the best when it comes to the detection of limit exceedances.
\\\\
\cite{LOZOWICKA2005} applied a neural network to prediction of a synthetic air quality index \textit{W} equal to the sum of daily mean concentrations of $PM10$, $SO_2$, $NO_2$ and $CO$ divided by their allowed maximum levels recommended by the World Health Organization. The authors used as an input meteorological variables (wind speed and direction, temperature, air humidity, air pressure, presence of an inversion layer) coming from a network of sensors and from a weather forecasting numerical model ALADIN. The authors concluded that the model used in the study performed with a reasonable accuracy and thus could have practical applications.
\\\\
\cite{AGIRREBASURKO2006430} compared performance of a linear regression model with two multilayer for prediction of hourly $NO_2$ and $O_3$ concentrations up to 8 hours ahead. Aside from the standard weather variables, the following factors were used as an input: radiation, thermal gradient, traffic intensity, sine and cosine of hour and the day of the week. The authors concluded that the MLP models outperformed the linear model. They also noted that the temporal variables proved to be important for the accuracy of prediction. 
\\\\
\cite{VLACHOGIANNI20111559} presented results of comparison of stepwise linear models with an artificial neural network for forecasting highest hourly and mean daily concentrations of $NO$, $NO_2$, $NO_x$, $CO$, $O_3$, $PM2.5$ and $PM10$ in Athens and Helsinki. In the case of Athens, the models were created separately for the cold and warm periods. In the case of Helsinki additional input variables - Monin-Obukhov length and the mixing height - were  used and proved useful. The authors reported, the difference between both types of models were insignificant, and thus the linear model was suggested to be useful.
\\\\
\cite{SINGH2012244} compared prediction capabilities of the following models: partial least squares regression model (PLSR), multivariate polynomial regression (MPR), three types of artificial neural networks - a multilayer perceptron (MLP), a radial basis function network (RBFN) and a generalised regression neural network (GRNN). The goal of the forecast was finding the concentrations of $SO_2$, $NO_2$ and respirable suspended particulate matter (RSPM) at five sites within the city of Lucknow, India. Prediction was based on the air quality data, as well as meteorological variables. Measurements of pollutant concentrations were taken twice a week for 24 hours. The nonlinear models performed better than the linear ones (PLSR), while the neural networks dominated the MPR models. Among the ANNs the GRNN performed best, with correlations between the predicted and actual concentrations equal to: 0.885 ($RSPM$), 0.596 ($NO_2$) and 0.729 ($SO_2$).
\\\\
\cite{Chellali2016} created three multilayer perceptrons with varying architectures and learning speeds in order to verify their capability of forecasting the hourly $PM10$ concentrations in the city of Algiers. Predictions were performed based on the historical $PM10$ levels and three weather factors: temperature, wind speed and relative humidity. Goodness of prediction was reported using the coefficient of determination ($R^2$) and the Index of Agreement (IA), which, in the case of the best model, were equal to 0.8 and 0.85, accordingly.
\\\\
\cite{PEREZ201622} presented results of prediction of hourly $PM2.5$ and $PM10$ concentrations up to 15 hours in advance in Santiago, Chile, made with a multilayer perceptron (MLP). The study was concentrated on night periods between April and August, when the particulate matter concentrations are relatively high compared to the remaining months. The neural network was trained with data from years 2010-2011 and tested with observations from 2012. Input to the neural network consisted of: hourly $PM2.5$ and $PM10$ concentrations, wind speed, relative humidity and thermal amplitude, forecasted thermal amplitude and forecasted ventilation index for the following day. The authors reported that the Pearson correlation coefficient $r$ between the actual and predicted concentrations ranged from about 0.9 for prediction 1 hour ahead to about 0.6 15 hours in advance. Prediction performed more than 15 hours ahead resulted in unsatisfactory accuracy (correlation lower than 0.5).
\\\\
\cite{Pawul2016} created multilayer perceptrons to predict daily average $PM10$ concentrations at 3 stations located in Krakow, Poland and operated by the Voivodship Inspectorate of Environmental Protection. The models were trained on data measured during the period from January 1 2014 to December 31 2015. The input of the neural networks consisted of the average $PM10$ level from the previous day, minimum, maximum and average temperature, average wind speed, average temperature from the previous day. Data set was split into training set (75\%), validation set (15 \%) and testing set (15\%). The best models found in the study were reported to achieve correlation between the actual and predicted concentrations higher than 0.9 and average errors equal to 12.64, 9.92 and 9.89 $\mu g / m^3$, depending on the station.
\\\\
\cite{BIANCOFIORE2017652} studied the applicability of a recurrent neural network (with Elman architecture) for the purpose of predicting the daily mean concentrations of $PM2.5$ and $PM10$ in Pescara, Italy,  1, 2 and 3 days ahead. The models were trained using the data measured between 2011 and 2012 and later tested with the data from 2013. The data set comprised: $PM$ and $CO$ concentrations, daily (probably mean) temperature, pressure, humidity, wind speed and direction. The RNN was compared with a multivariate linear model and a multilayer perceptron. The RNN outperformed the other two models, achieving the following scores for one day ahead prediction: coefficient of correlation R = 0.89, normalised mean square error = 0.559 for $PM2.5$ and R = 0.85, NMSE = 0.0624 for $PM10$. Prediction goodness was found to be the lower, the longer the prediction time interval. The authors pointed out that adding $CO$ concentrations as an input factor resulted in slightly better accuracy of all models, especially the MLR.
\\\\
\cite{LUO201834} proposed a hybrid system for prediction of daily $PM10$ concentrations in Beijing and Harbin, China. The system was composed of two models: one for the original time series and the other for forecasting errors produced by the first model. Both of them were extreme learning machines - a type of a single hidden layer neural network. The hyperparameters of the neural networks were tweaked, using the cuckoo search optimization algorithm. As a preprocessing stage, the original and the error time series were decomposed with fast ensemble empirical mode decomposition (FEEMD) and variational mode decomposition (VMD), accordingly. The final forecast was composed of the original predicted concentration and a correction, being the output of the second model.
The data set used in the study was comprised of daily $PM10$ concentrations (no weather factors were taken into consideration) taken between January 1, 2015 and August 31, 2016. The presented model was compared with and ARIMA model, a generalised regression neural network model with EEMD decomposition, a support vector regression model optimised with the grey wolf optimisation algorithm and using complementary ensemble empirical mode decomposition (CEEMD), a standard ELM, an ELM with CEEMD and differential evolution optimisation (DE), an ELM with FEEMD but without the VMD decomposition. The authors reported that their model outperformed all of the remaining ones, achieving the following goodness of prediction scores: MAE = 9.191 $\mu g / m^3$, RMSE = 12.630 $\mu g / m^3$, MAPE = 15.320 \%.
\\\\
\cite{LI2017997} proposed a long short-time memory extended neural network model (LSTME) for predicting hourly concentrations of $PM2.5$ at 12 monitoring stations across Beijing, China. The data used in the study included: hourly $PM2.5$ concentrations, temperature, humidity, wind speed, visibility, month of year (1-12), hour of day (00:00 to 23:00). Time lag of up to 8 hours was reported to be best of the considered ones (between 4 and 16 hours). 
The authors concluded that the proposed LSTME model outperformed other studied models when it comes to 1 hour ahead prediction: a spatiotemporal deep learning model (STDL), a time delay neural network (TDNN), an autoregressive moving average model (ARMA), a support vector regression model (SVR) and an LSTM neural network without the auxiliary weather and temporal factors. The authors tested also the capabilities of predicting the $PM2.5$ concentrations up to 24 hours in advance. In that case the LSTME model was characterised by the following statistics: root mean square error (RMSE) = 12.6 $\mu g / m^3$ mean absolute error (MAE) = 14.68 $\mu g / m^3$, mean absolute percentage error (MAPE) = 31.47\%.
\\\\
\cite{DOTSE2018358} creating a predictive model in two steps. Firstly, the best subset of input variables was sought after using a random forest model with parameters optimised by a genetic algorithm. Then, the best subset of the input variables was used to train a back-propagation neural network (BPNN).
The final model was utilised to predict the mean $PM10$ concentrations in Brunei Darussalam. The gathered observations included: daily mean $PM10$ concentrations, daily rainfall, minimum, average and maximum temperature, temperature amplitude, relative humidity, max and average wind speed, wind direction (transformed using sine and cosine functions). The data set was supplemented with temporal factors: month of the year and day of the week. Both of them were transformed with sine and cosine functions, similarly to the wind direction observations. Missing values in records were replaced using the Expectation Maximization Based algorithm (EMB).
The authors compared the performance of the final model with a standard BPNN and a BPNN directly optimised by a genetic algorithm. The model using the random forest optimisation was found to consistently outperform the other two models, scoring the following goodness of prediction values: minimum correlation between the actual and predicted concentrations r = 0.8726, maximum mean absolute error = 8.2211 $\mu g / m^3$, maximum root mean square error = 11.0044 $\mu g / m^3$.
\\\\
While the regression and neural network models are widely used for prediction of air quality, there have been also attempts at applying other techniques for this purpose e.g. autoregressive integrated moving average (ARIMA), decision tree, (least squares) support vector machine/regression (SVM/SVR), hidden Markov model (HMM). 

\subsection{ARIMA models}
\cite{DIAZROBLES20088331} combined an ARIMAX (multivariate ARIMA) model with a multilayer perceptron in order to predict the daily maximum moving averages of $PM10$ concentrations in Temuco, Chile. The ARIMAX model was created with the following inputs: autoregressive and moving average components for $PM10$ of order 1 (ARIMA(1, 0, 1)), maximum hourly $PM10$ concentration of the previous day, wind speed, minimum and maximumimum temperature. The output from the ARIMAX model was used as the input to the ANN along with: prediction errors from the ARIMAX, the max $PM10$ concentration of the previous day, wind speed, minimum and maximumimum temperature. The MLP was trained using the Levenberg–Marquardt algorithm. Performance of the hybrid model was compared with a multivariate linear and individual ARIMAX and ANN models, proving to be the most accurate of them with coefficient of determination $R^2$ = 0.9828, RMSE = 8.80 $\mu g / m^3$, MAE = 6.74 $\mu g / m^3$. 
\\\\
\cite{CATALANO201669} proposed using a seasonal ARIMAX model in order to forecast peak $NO_2$ concentrations near the Marylebone road located in London, United Kingdom. Coefficients of the SARIMAX model were estimated using the maximum likelihood method and a Kalman filter. The following variables were used: hourly mean concentrations of $NO_2$, hourly traffic volume, hourly mean wind speed, hourly mean wind direction, hourly mean temperature. The SARIMAX model was compared with a multivariate linear regression model, a multilayer perceptron and an ensemble model combining the SARIMAX and ANN. The last model proved to be the most accurate with correlation between predicted and observed concentrations r = 0.92 and MAPE = 19.32\%. The SARIMAX model was reported to outperform the ANN when it comes to forecasting peak concentrations.

\subsection{Models based on support vector machines}
Support Vector Regression (SVR) is a modified variant of a Support Vector Regression which is suited for fitting a linear function to a set of. Its goal is to find a function $f(x)$ that approximates the available data points in such a way that in all cases the absolute difference between the actual value of the response variable and the value of the fitted function is not higher than $\epsilon$ (an input parameter). An additional condition taken into consideration states that the magnitude of input weights should be as small as possible. The optimisation problem can be formulated as shown in equation \ref{eq:models-svr-optimisation}.
\begin{equation}\label{eq:models-svr-optimisation}
\begin{gathered}
    \text{minimize}\, \frac{1}{2} {\lVert {w} \rVert}^2 \\
    \text{subject to}
    \begin{cases}
        y_i - (\langle \bm{w}, \bm{x_i} \rangle + w_0, & \leq \epsilon \\
        (\langle \bm{w}, \bm{x_i} \rangle + w_0) - y_i, & \leq \epsilon
    \end{cases}
\end{gathered}
\end{equation}
Symbols used in equation \ref{eq:models-svr-optimisation} have the following meaning: $y_i$ is the $i^{th}$ actual value of the response variable, $\bm{w}$ is the vector of input weights, $\bm{x_i}$ is the $i^{th}$ vector of predictor values, $\langle \cdot, \cdot \rangle$ is the dot product, $\epsilon$ is the assumed tolerance margin. 
In some cases the function $f(x)$ may not exist. Because of that additional variables $\xi, {\xi}^*$ representing the exceedance of the tolerance limit are introduced into the problem formulation (equation \ref{eq:models-svr-optimisation-soft}).

\begin{equation}\label{eq:models-svr-optimisation-soft}
\begin{gathered}
    \text{minimize}\, \frac{1}{2} {\lVert {w} \rVert}^2 + C\sum_{i = 1}^{n} ({\xi}_i + {{\xi}_i}^*) \\
    \text{subject to}
    \begin{cases}
        y_i - (\langle \bm{w}, \bm{x_i} \rangle + w_0, & \leq \epsilon + {\xi}_i \\
        (\langle \bm{w}, \bm{x_i} \rangle + w_0) - y_i, & \leq \epsilon + {{\xi}_i}^* \\
        {\xi}_i + {{\xi}_i}^* \geq 0
    \end{cases}
\end{gathered}
\end{equation}
The $C$ coefficient controls the strength of the penalty corresponding to the data points laying outside the tolerance margin. The problem stated in the equation \ref{eq:models-svr-optimisation-soft} is an example of a quadratic programming problem and can be solved using the Lagrange multipliers method. For a more detailed description of the procedure refer to \cite{SMOLA2003}.
\\\\
It is worth noting that an SVR model can be adapted to fitting nonlinear functions transforming the data points using a kernel function and performing the optimisation in the new feature space. A kernel function takes the form of a dot product shown in equation \ref{eq:models-svr-kernel} because the optimisation procedure actually requires calculating the dot products of the input vectors. In this study a radial basis function kernel defined in equation \ref{eq:models-svr-kernel-rbf} was used.

\begin{equation}\label{eq:models-svr-kernel}
K(\bm{x}, \bm{x'}) = \langle \Phi(\bm{x}), \Phi(\bm{x'}) \rangle
\end{equation}

\begin{equation}\label{eq:models-svr-kernel-rbf}
K(\bm{x}, \bm{x'}) = e^{-\gamma {\lVert \bm{x} - \bm{x'} \rVert}^2}
\end{equation}

There have been at least a few studies which tested the applicability of Support Vector Regression (or similar methods) to the problem of air quality forecasting. For example Yeganeh et al. proposed a model combining the partial least squares method (used for dimensionality reduction) with a support vector machine \cite{YEGANEH2012357}. The goal of prediction were the hourly and daily $CO$ concentrations in the Rey monitoring station in Tehran, Iran. It is unclear, however, how long in advance the concentrations were forecasted. The data used in the study included the following variables: concentrations of $PM10$, total hydrocarbons, nitrogen oxides ($NO_x$), methane ($CH_4$), $SO_2$ and $O_3$, temperature, relative humidity, wind direction and speed. The observations were split into a training set (75\%) and a test set (25\%). For the purpose of hourly $CO$ forecast measurements were narrowed to those taken during May, August, November 2010 and February 2011. Parameters of the SVM were optimised using grid search. The new model was compared with a standard SVM. The authors reported that the hybrid model provided more accurate forecasts with RMSE ranging from 0.383 to 1.242 particles per million (ppm), mean absolute relative error (MARE) from 0.073 to 0.329 ppm and coefficient of determination $R^2$ from 0.777 to 0.85 for prediction of hourly concentrations and RMSE = 0.711, MARE = 0.096 and $R^2$ = 0.654 for daily concentrations. The authors also noted that the new model took less time to train and fine-tune.
\\\\
Sun et al. applied a least squares support vector machine (LSSVM) to the problem of prediction of daily average $PM2.5$ concentrations in Baoding City, China \cite{SUN2017144}. An LSSVM model is a modified SVM which can be used for regression problems. Since it solves a set equations instead of a quadratic programming problem, it is characterised by higher operation speed than a standard SVM. The authors combined the forecasting model with the PCA technique for feature selection and dimensionality reduction of the input data and with the cuckoo search algorithm used for optimising the parameters of the LSSVM. The data comprised the following factors: daily average concentrations of $PM10$, $SO_2$, $CO$, $NO_2$ and $O_3$, minimum and maximum daily temperatures. The proposed model, compared with a basic LSSVM and a generalised regression neural network (GRNN), was reported to achieve the lowest prediction errors with MAE = 18.84 $\mu g / m^3$, RMSE = 14.47 $\mu g / m^3$ and MAPE = 12.56\%.
\\\\
Yang et al. presented a support vector regression model (STSVR) incorporating a spatial clustering algorithm in order to predict hourly $PM2.5$ concentrations in Beijing, China \cite{YANG201812}. The monitoring stations were grouped with the GeoSOM method based on the self-organising maps using the Euclidean distance as a similarity measure with Davies-Bouldin and Sil indexes as the basis for choosing the number of clusters. The influence of pollutant concentrations from the neighbouring stations was estimated based on the wind direction and included in the system as weights of the individual local models. The data used by the authors was collected at 35 monitoring stations and included: hourly $PM2.5$ concentrations, temperature, relative humidity, precipitation, wind force and direction. The authors performed tests, comparing the proposed model with an ARIMAX model (only one station), a global / local space-time neural network(s) (STANN) and a global SVR model. Performance evaluation was conducted on the whole data set (no separate test set was created). The results were grouped based on the number of hours in advance that the prediction was made for: 1 - 6h, 7 - 12h and 13 - 24 h. The proposed model outperformed most of the remaining ones - the global SVR scored higher MAE only in the case of the 1 - 6h prediction. STSVR was characterised by MAE = 19.76 $\mu g / m^3$ (1 - 6h), 31.81 $\mu g / m^3$ (7 - 12h) and 53.79 $\mu g / m^3$ (13 - 24h). On the other hand some of the local SVR models predicted future concentrations with lower errors than the global SVR.

\subsection{Fuzzy time series models}
\cite{CHENG20112016} proposed a fuzzy time series model (FTS) for predicting daily maximum ozone concentrations in Hsinchu City, Taiwan. The method presented in the study is based on the idea that, in order to predict a value of a variable, it would be reasonable to look for historical observations similar to the current one and find successive measurements. In order to make it possible, the data were fuzzified and grouped based on the time when the measurements were taken. Predicting future $O_3$ concentrations was then achieved by calculating the weighted average of the found defuzzified past observations. Division of the variable domain into intervals (creating the \textit{universe of discourse}) was performed using two algorithms: the cumulative probability distribution approach (CPDA) and the uniform discretion mehod (UMD). 
The data set comprised concentrations of: $O_3$, $SO_2$, $NO2$, $PM10$ and $CO$ and five weather factors: wind speed and direction, temperature, relative humidity and solar radiation. The proposed method was compared with the following models: AR, MA, ARMA, a FTS model proposed by \cite{CHEN1996311} for prediction of enrolment, a FTS model by \cite{YU2005609} applied to stock market index forecasting. It was reported that the new model outperformed the other ones, scoring RMSE = 3.22 ppb (particles per billion) and MAPE = 10\% for the CPDA method and RMSE = 3.35 ppb, MAPE = 9\% for UMD.
\\\\
\cite{DOMANSKA20127673} presented a FTS model for forecasting weather factors and concentrations of the following pollutants: $PM10$, $PM2.5$, $SO_2$, $NO$, $CO$ and $O_3$ for a specific date and time (e.g. 24 hours from the current time). In this case the fuzzified observations were grouped based on the fractional distance between them. The data set used in the study included the following variables: weather forecast from the COSMO model (wind speed, wind direction, temperature, dew point temperature, cloud cover, ground fog, snow amount, water content of snow, base/top height of convection cloud above the mean sea level),  measured meteorological situation (cloud cover, wind speed, pressure, temperature, water vapour pressure, humidity, x and y coordinates of wind direction vector), pollutant concentrations. Tests discussed in the article concerned the concentrations of $PM10$ 12, 24 and 36 hours in advance. The authors reported that the average percentage errors were equal to: 20.27\% for 12h, 22.19\% for 24h, 21.46\% for 36 h. The authors noted that the proposed model requires a large database of historical observations.
\\\\
\cite{GULERDINCER2018157} presented a fuzzy time series model which utilises a k-medoids clustering algorithm during the fuzzification stage. According to the authors such a model can be used even with data containing outliers, which is its main advantage when compared to the earlier models (for example \cite{CHENG20112016}). The data set used in the study was made up of measurements of weekly $SO_2$ concentrations taken at 65 monitoring stations in Turkey. The authors compared their model with other FTS models using different clustering strategies - c-means and the Gustafson-Kessel algorithm. Tests were performed separately for each of the monitoring stations. In many cases the new model provided the most accurate predictions with the root mean square error ranging from 8.84 to 55.30 (the unit of $SO_2$ concentrations was not specified in the article).

\subsection{Decision trees}
\cite{SIWEK2016} focused in their study on the problem of selecting the optimal subset of input variables for a predictive model. The authors used for this purpose stepwise linear fit and a genetic algorithm. After generating the best variable subset they used it as input to the following models: a random forest decision tree (RF), a support vector regression model (SVR), a multilayer perceptron (MLP) and a radial basis function neural network (RBF). The data set used in the study was comprised of measurements taken in Warsaw, Poland, in the 2001-2014 period.
The goal of prediction was the mean daily (24 hour) concentrations of $PM10$, $SO_2$, $NO_2$ and $O_3$ during the next day. In the case of $PM10$ the final set of input variables was comprised of:
\begin{enumerate}
    \item minimum, average and maximum pollution concentrations,
    \item minimum, average and maximum temperature,
    \item max humidity,
    \item average solar irradiance,
    \item minimum, average and maximum wind speed,
    \item pollution level and humidity predicted by linear trend,
    \item a few hourly pollution concentrations (not all 24 values were used),
    \item representation of the current season,
    \item type of the day - working or weekend.
\end{enumerate}
The researchers reported that the random forest model proved to be the most accurate, with MAPE = 17.92 $\%$, MAE = 5.405$\mu g / m^3$, RMSE = 8.36 $\mu g / m^3$ and the coefficient of correlation equal to 0.924. They also attempted to create an ensemble model combining the neural predictors into one, using weights proportional to the accuracy of a single model and, alternatively, a random forest model receiving as an input the predictions made by the other models. The authors concluded, however, that these complex models performed worse than an individual random forest forecaster.

\subsection{Hidden Markov model}
\cite{SUN201393} applied a hidden Markov model (HMM) in order to predict exceedances of $PM2.5$ concentration limit in the cities of Concord and Sacramento in California, USA. Data used in study include: concentrations of $PM2.5$, $NO$, $NO_2$, $CO$, $SO_2$. In the case of Sacramento additional variables were available: concentrations of methane hydrocarbons, wind speed, temperature, relative humidity, dew point and precipitation. Training data were grouped into 96 hour time windows (with missing values being imputed) and compressed using the wavelet decomposition method. The authors tested HMMs with four emission distribution functions: normal, log-normal, Gamma and GEV. The model with the log-normal distribution was found to outperform the remaining ones in the case of Concord, scoring true prediction rate (TPR) of 66.67\%, while in the case of Sacramento model with GEV distribution was found to have the highest TPR equal to 100\%.


\begin{landscape}
\begin{table}[htp]
\centering
\footnotesize
\rowstripes
\caption{Summary of results reported in related work}
\label{tab:related-work-results}
\begin{tabular}{p{0.2\linewidth - 2\tabcolsep}
    |p{0.1\linewidth - 2\tabcolsep}
    |p{0.15\linewidth - 2\tabcolsep}
    |p{0.2\linewidth - 2\tabcolsep}
    |p{0.15\linewidth - 2\tabcolsep}
    |p{0.2\linewidth - 2\tabcolsep}}
\toprule
Source & City & Models & Prediction goal & Data time span & Results of the best model \\ \midrule
\cite{Paschalidou2009} & Athens, Greece & MLR + PCA & $ln(O_3)$ at a given time & 2001 - 2004 & \makecell[tl]{$R^2$ = 0.67 - 0.84} \\
\cite{COBOURN20103015} & Louisville, USA & NLR & daily maximum $PM2.5$ & 2003 - 2008 & \makecell[tl]{MAE = 4.1 - 4.7 $\mu g / m^3$\\NMAE = 20 - 25 $\%$\\IA = 0.86 - 0.88} \\
\cite{Sotoudeheian2014} & Tehran, Iran & MLR, NLR & $ln(O_3)$ at a given time & 2009 - 2010 & \makecell[tl]{NLR\\$R^2$ = 0.51 - 0.55\\RMSE = 14.7 - 32.9 $\mu g / m^3$\\MAE = 13 - 30.1 $\mu g / m^3$} \\
\cite{WESTERLUND201422} & Bogota, Colombia & an ensemble  of MLRs, ANN & daily means of $PM10$, $CO$, $NO_x$, $NO_2$, $SO_2$, $O_3$ & 2005 - 2010 & \makecell[tl]{Ensemble:\\The results were expressed\\relatively to the best\\models} \\
\cite{GARCIANIETO201450} & Gijón, Spain & multivariate adaptive regression splines (MARS) & monthly means of $NO_2$, $SO_2$ and $PM10$ & 2006 - 2008 & \makecell[tl]{$R^2$ = 0.92 ($NO_2$)\\$R^2$ = 0.95 ($SO_2$)\\$R^2$ = 0.77 ($PM10$)} \\
\cite{GARDNER1999709} & London, UK & MLR, MLP & hourly $NO_2$ and $NO_x$ concentrations 1h and 24h in advance & 1990 - 1991 & \makecell[tl]{MLP (20, 20)\\$NO_2$, 24 hours in advance\\MAE = 9.5 ppb\\RMSE = 17.1 ppb\\ $r^2$ =  0.51 (corr. coeff)} \\
\cite{PEREZ20024555} & Santiago, Chile & MLP & the maximum of 24h moving averages of $PM10$ & 1998-2000 & \makecell[tl]{MLP (4, 3)\\percentage error: 16$\%$} \\
\bottomrule
\end{tabular}
\end{table}
\end{landscape}

\begin{landscape}
\begin{table}[htp]
\centering
\footnotesize
\rowstripes
\begin{tabular}{p{0.2\linewidth - 2\tabcolsep}
    |p{0.1\linewidth - 2\tabcolsep}
    |p{0.15\linewidth - 2\tabcolsep}
    |p{0.2\linewidth - 2\tabcolsep}
    |p{0.15\linewidth - 2\tabcolsep}
    |p{0.2\linewidth - 2\tabcolsep}}
\toprule
Source & City & Models & Prediction goal & Data time span & Results of the best model \\ \midrule
\cite{KUKKONEN2003} & Helsinki, Finland & a deterministic model, a linear model, MLP, heteroscedastic ANN with Gaussian noise & hourly $NO_2$ and $PM10$ concentrations 24h in advance & 1996 - 1999 & \makecell[tl]{heteroscedastic ANN\\with Gaussian noise\\$NO_2$:\\IA = 0.73 - 0.77\\$r^2$ =  0.59 - 0.70\\\\$PM10$:\\$r^2$ = 0.31 - 0.42} \\
\cite{CORANI2005513} & Milan, Italy & MLP, lazy learning model & Daily maximum 8h moving average of $O_3$, daily mean of $PM10$ & 1999 - 2001 ($O_3$)1999 - 2002 ($PM10$) & \makecell[tl]{lazy learning\\$O_3$:\\$r$ = 0.86\\MAE = 15.49\\IA = 0.92\\\\$PM10$:\\$r$ = 0.90\\MAE = 8.25\\IA = 0.94} \\
\cite{LOZOWICKA2005} & Krakow, Poland & MLP & sum of daily mean concentrations of $PM10$, $SO_2$, $NO_2$ and $CO$ during the next day divided by their allowed maximum levels & winter periods between 1998 and 2001 & \makecell[tl]{MLP (5, 1)\\RMSE = 0 - 0.211} \\
\cite{AGIRREBASURKO2006430} & Bilbao, Spain & MLR, MLP & $O_3$ and $NO_2$ levels up to 8h in advance & 1993 - 1994 & \makecell[tl]{MLP, single hidden layer\\(unknown number\\of neurons)\\$NO_2$\\r = 0.501 - 0.663\\NMSE = 0.004 - 0.02\\\\$O_3$\\r = 0.426 - 0.575\\NMSE = 0.0003 - 0.065} \\ 
\bottomrule
\end{tabular}
\end{table}
\end{landscape}

\begin{landscape}
\begin{table}[htp]
\centering
\footnotesize
\rowstripes
\begin{tabular}{p{0.2\linewidth - 2\tabcolsep}
    |p{0.1\linewidth - 2\tabcolsep}
    |p{0.15\linewidth - 2\tabcolsep}
    |p{0.2\linewidth - 2\tabcolsep}
    |p{0.15\linewidth - 2\tabcolsep}
    |p{0.25\linewidth - 2\tabcolsep}}
\toprule
Source & City & Models & Prediction goal & Data time span & Results of the best model \\ \midrule
\cite{VLACHOGIANNI20111559} & Athens, Greece, Helsinki, Finland & MLR, MLP & daily maximum $PM10$ and $NO_x$ (averaged by hour), mean daily $PM10$ & 2005 & \makecell[tl]{MLP (architecture not mentioned)\\Athens:\\hourly maximum:\\r = 0.62 - 0.85 ($NO_x$)\\r = 0.32 - 0.72 ($PM10$)\\daily average:\\r = 0.6 - 0.9 ($PM10$\\\\Helsinki:\\hourly maximum:\\r = 0.44 - 0.79 ($NO_x$)\\r = 0.73 - 0.79 ($PM10$)\\daily average:\\R = 0.80 - 0.91 ($PM10$)} \\
\cite{SINGH2012244} & Lucknow, India & partial least squares regression, multivariate polynomial regression, MLP, general regression NN, radial basis function NN & $SO_2$, $NO_2$, respirable suspended particulate matter (RSPM) & 2005–2009 & \makecell[tl]{GRNN (985 units in the pattern\\layer and 2 units in the summation\\layer)\\r =  0.932 (RSPM)\\r = 0.768 ($NO_2$)\\r = 0.729 ($SO_2$)} \\
\cite{Chellali2016} & Algiers, Algieria & MLP & mean daily $PM10$ & 2002–2006 & \makecell[tl]{MLP (15)\\IA = 0.81\\$R^2$ = 0.75\\RMSE = 10.75 $\mu g/m^3$\\} \\
\cite{PEREZ201622} & Santiago, Chile & MLR, MLP, persistence model & hourly $PM2.5$ and $PM10$ concentrations up to 15 hours in advance & 2010 - 2012 & \makecell[tl]{MLP (unknown architecture)\\15 hours ahead\\r = 0.6} \\
\cite{Pawul2016} & Krakow, Poland & MLP & mean daily $PM10$ & 2014-2015 & \makecell[tl]{MLP (13), (15), (18)\\r = 0.908 - 0.933} \\
\bottomrule
\end{tabular}
\end{table}
\end{landscape}

\begin{landscape}
\begin{table}[htp]
\centering
\footnotesize
\rowstripes
\begin{tabular}{p{0.2\linewidth - 2\tabcolsep}
    |p{0.1\linewidth - 2\tabcolsep}
    |p{0.15\linewidth - 2\tabcolsep}
    |p{0.2\linewidth - 2\tabcolsep}
    |p{0.15\linewidth - 2\tabcolsep}
    |p{0.25\linewidth - 2\tabcolsep}}
\toprule
Source & City & Models & Prediction goal & Data time span & Results of the best model \\ \midrule
\cite{BIANCOFIORE2017652} & Pescara, Italy & Recurrent Elman NN, MLR, MLP & daily mean concentrations of $PM2.5$ and $PM10$ 1, 2 and 3 days in advance & 2011 - 2013 & \makecell[tl]{Elman ANN,\\1 day in advance\\$PM2.5$:\\r = 0.89\\NRMSE = 0.559\\\\$PM10$:\\r = 0.85\\NMSE = 0.0624} \\
\cite{LUO201834} & Beijing, China & ARIMA, GRNN, Extreme Learning Machine + time series decomposition + Cuckoo Search & daily $PM10$ concentrations & 2015 - 2016 & \makecell[tl]{Extreme Learning Machine\\MAE = 9.191 $\mu g / m^3$\\RMSE = 12.630 $\mu g / m^3$\\MAPE = 15.320 $\%$} \\
\cite{LI2017997} & Beijing, China & ARMA, SVR, Time Delay NN, Spatiotemporal Deep Learning NN, LSTM ANN & hourly mean $PM2.5$ up to 24h in advance & 2014 - 2016 & \makecell[tl]{LSTM (1000 nodes in each layer),\\13 - 24h in advance\\RMSE = 12.6 $\mu g / m^3$\\MAE = 14.68 $\mu g / m^3$\\MAPE = 31.47$\%$} \\
\cite{DOTSE2018358} & Brunei Darussalam & MLP + random forest input selection + genetic algorithm optimisation & daily mean $PM10$ & 2009 - 2013 & \makecell[tl]{MLP (number of hidden neurons\\between 1 and 30,\\ final architecture unknown)\\Min r = 0.8726\\Max MAE = 8.2211 $\mu g / m^3$\\Max RMSE = 11.0044 $\mu g / m^3$} \\
\cite{DIAZROBLES20088331} & Temuco, Chile & MLR, ARIMAX, ARIMAX + MLP (hybrid) & daily maximum moving averages of $PM10$ & April 1 - September 30 2006 & \makecell[tl]{ARIMAX + MLP (hybrid)\\$R^2$ = 0.9828\\RMSE = 8.80 $\mu g / m^3$\\MAE = 6.74 $\mu g / m^3$} \\
\cite{CATALANO201669} & London, UK & MLR, Seasonal ARIMAX + Kalman filter, MLP & maximum daily $NO_2$ & 2006-2007 & \makecell[tl]{MLP (7):\\R = 0.92\\MAPE = 19.32 $\%$} \\
\bottomrule
\end{tabular}
\end{table}
\end{landscape}

\begin{landscape}
\begin{table}[htp]
\centering
\footnotesize
\rowstripes
\begin{tabular}{p{0.2\linewidth - 2\tabcolsep}
    |p{0.1\linewidth - 2\tabcolsep}
    |p{0.15\linewidth - 2\tabcolsep}
    |p{0.2\linewidth - 2\tabcolsep}
    |p{0.15\linewidth - 2\tabcolsep}
    |p{0.25\linewidth - 2\tabcolsep}}
\toprule
Source & City & Models & Prediction goal & Data time span & Results of the best model \\ \midrule
\cite{YEGANEH2012357} & Tehran, Iran & partial least squares method + SVM & hourly and daily $CO$ concentrations & 2007 - 2011 & \makecell[tl]{Hourly:\\MARE = 0.073 - 0.329 ppm\\$R^2$ = 0.777 - 0.85\\RMSE  = 0.383 - 1.242 ppm\\\\Daily:\\MARE = 0.096 ppm\\$R^2$ = 0.654\\RMSE = 0.711 ppm} \\
\cite{SUN2017144} & Baoding, China & LSSVM, LSSVM + PCA + Cuckoo Search, GRNN & daily average $PM2.5$ & January 1 - December 10 2015 & \makecell[tl]{LSSVM + PCA + Cuckoo Search:\\MAE = 18.84 $\mu g / m^3$\\RMSE = 14.47 $\mu g / m^3$\\MAPE = 12.56$\%$} \\
\cite{YANG201812} & Beijing, China & ARIMAX, SVR, SVR + spatial clustering, space-time NN & hourly $PM2.5$ 1 - 24h in advance & March - April 2014 & \makecell[tl]{SVR + spatial clustering:\\MAE = 19.76 $\mu g / m^3$ (1 - 6h)\\MAE = 31.81 $\mu g / m^3$ (7 - 12h)\\MAE = 53.79 $\mu g / m^3$ (13 - 24h)} \\
\cite{CHENG20112016} & Hsinchu, Taiwan & FTS, AR, MA, ARMA & daily maximum $O_3$ & 2017 & \makecell[tl]{FTS:\\MAPE = 10$\%$\\RMSE = 3.22 ppb} \\
\cite{DOMANSKA20127673} & Poland (city/cities not specified) & FTS & hourly concentrations of $PM10$, $PM2.5$, $SO_2$, NO, $CO$ and O3 for a chosen time in advance (results for 12, 24 and 36 h) & 2004-2012 & \makecell[tl]{average percentage error:\\12h - 20.27$\%$\\24h - 22.19$\%$\\36h - 21.46$\%$} \\
\cite{GULERDINCER2018157} & Turkey & FTS & weekly $SO_2$ concentrations & 2013-2016 & \makecell[tl]{RMSE = 8.84 to 55.30\\(units unknown)} \\
\bottomrule
\end{tabular}
\end{table}
\end{landscape}

\begin{landscape}
\begin{table}[htp]
\centering
\footnotesize
\rowstripes
\begin{tabular}{p{0.2\linewidth - 2\tabcolsep}
    |p{0.1\linewidth - 2\tabcolsep}
    |p{0.15\linewidth - 2\tabcolsep}
    |p{0.2\linewidth - 2\tabcolsep}
    |p{0.15\linewidth - 2\tabcolsep}
    |p{0.25\linewidth - 2\tabcolsep}}
\toprule
Source & City & Models & Prediction goal & Data time span & Results of the best model \\ \midrule
\cite{SIWEK2016} & Warsaw, Poland & (Random Forest, SVR, MLP, Radial Basis Function NN) + input selection (stepwise fit, genetic algorithm) & mean daily concentrations of $PM10$, $SO_2$, $NO_2$ and $O_3$ during the next day & 2001-2014 & \makecell[tl]{Random Forest with input\\selection based on\\a generic algorithm\\MAE = 5.405 $\mu g / m^3$\\MAPE = 17.92 $\%$\\r = 0.924\\RMSE = 8.36 $\mu g / m^3$} \\
\cite{SUN201393} & Concord and Sacramento, USA & hidden Markov model + wavelet decomposition & exceedances of $PM2.5$ concentration limit & 1999-2008 (Concord), 2000 - 2011 (Sacramento) & \makecell[tl]{Concord:\\HMM with a log-normal\\distribution function\\True Prediction Rate: 	91.67$\%$\\Sacramento:\\HMM with a GEV distribution\\function\\TPR: 100$\%$} \\
\bottomrule
\end{tabular}
\end{table}
\end{landscape}


\begin{landscape}
\begin{table}[htp]
\centering
\small
\rowstripes
\caption{Air quality variables used in related work}
\label{tab:related-work-air-quality-variables}
\begin{tabular}{l|l|l|l|l|l|l|l|l|l}
\toprule
Source & $PM2.5$ & $PM10$ & $CO$ & $CO_2$ & $NO$ & $NO_2$ & $SO_2$ & $O_3$ & Hydrocarbons \\ \midrule
\cite{Paschalidou2009} &  &  &  &  & \checkmark & \checkmark &  & \checkmark &  \\
\cite{COBOURN20103015} & \checkmark &  &  &  &  &  &  &  &  \\
\cite{Sotoudeheian2014} &  & \checkmark &  &  &  &  &  &  &  \\
\cite{WESTERLUND201422} &  &  & \checkmark &  &  & \checkmark & \checkmark & \checkmark &  \\
\cite{GARCIANIETO201450} &  & \checkmark & \checkmark &  & \checkmark & \checkmark & \checkmark & \checkmark &  \\
\cite{GARDNER1999709} &  &  &  &  & \checkmark & \checkmark &  &  &  \\
\cite{PEREZ20024555} &  & \checkmark &  &  &  &  &  &  &  \\
\cite{KUKKONEN2003} &  & \checkmark &  &  & \checkmark & \checkmark &  &  &  \\
\cite{CORANI2005513} &  & \checkmark & \checkmark &  & \checkmark & \checkmark & \checkmark & \checkmark &  \\
\cite{LOZOWICKA2005} &  & \checkmark & \checkmark &  &  & \checkmark & \checkmark &  &  \\
\cite{AGIRREBASURKO2006430} &  &  &  &  &  & \checkmark &  & \checkmark &  \\
\cite{VLACHOGIANNI20111559} & \checkmark & \checkmark & \checkmark &  & \checkmark & \checkmark &  & \checkmark &  \\
\cite{SINGH2012244} &  &  &  &  &  & \checkmark & \checkmark &  &  \\
\cite{Chellali2016} &  & \checkmark & \checkmark & \checkmark &  &  & \checkmark & \checkmark & \checkmark \\
\cite{PEREZ201622} & \checkmark & \checkmark &  &  &  &  &  &  &  \\
\cite{Pawul2016} &  & \checkmark &  &  &  &  &  &  &  \\
\cite{BIANCOFIORE2017652} & \checkmark & \checkmark & \checkmark &  &  &  &  &  &  \\
\cite{LUO201834} &  & \checkmark &  &  &  &  &  &  &  \\
\cite{LI2017997} &  &  &  &  &  &  &  &  &  \\
\cite{DOTSE2018358} &  & \checkmark &  &  &  &  &  &  &  \\
\cite{DIAZROBLES20088331} &  & \checkmark &  &  &  &  &  &  &  \\
\cite{CATALANO201669} &  &  &  &  &  & \checkmark &  &  &  \\
\cite{YEGANEH2012357} &  & \checkmark &  &  & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark \\
\cite{SUN2017144} &  & \checkmark & \checkmark &  &  & \checkmark & \checkmark & \checkmark &  \\
\cite{YANG201812} & \checkmark &  &  &  &  &  &  &  &  \\
\cite{CHENG20112016} &  & \checkmark & \checkmark &  &  & \checkmark & \checkmark & \checkmark &  \\
\cite{DOMANSKA20127673} & \checkmark & \checkmark & \checkmark &  & \checkmark &  & \checkmark & \checkmark &  \\
\cite{GULERDINCER2018157} &  &  &  &  &  &  & \checkmark &  &  \\
\cite{SIWEK2016} &  & \checkmark &  &  &  & \checkmark & \checkmark & \checkmark &  \\
\cite{SUN201393} & \checkmark &  &  & \checkmark & \checkmark & \checkmark & \checkmark &  & \checkmark \\ \bottomrule
\end{tabular}
\end{table}
\end{landscape}



\begin{landscape}
\begin{table}[htp]
\centering
\scriptsize
\rowstripes
\caption{Weather variables used in related work}
\label{tab:related-work-weather-variables}
\begin{tabular}{p{0.3\linewidth - 2\tabcolsep}
    |l|l|l|l|l|l|l|l}
\toprule
Source & Temperature & Dew Point & Humidity & Pressure & Rainfall & Solar radiation & Wind speed & Wind direction \\ \midrule
\cite{Paschalidou2009} & \checkmark &  & \checkmark & \checkmark &  & \checkmark & \checkmark & \checkmark \\
\cite{COBOURN20103015} & \checkmark & \checkmark & \checkmark &  &  &  & \checkmark &  \\
\cite{Sotoudeheian2014} & \checkmark &  & \checkmark &  &  &  & \checkmark & \checkmark \\
\cite{WESTERLUND201422} & \checkmark &  &  &  & \checkmark & \checkmark & \checkmark & \checkmark \\
\cite{GARCIANIETO201450} &  &  &  &  &  &  &  &  \\
\cite{GARDNER1999709} &  &  &  &  &  &  & \checkmark &  \\
\cite{PEREZ20024555} & \checkmark &  & \checkmark &  &  &  & \checkmark &  \\
\cite{KUKKONEN2003} & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark &  & \checkmark &  \\
\cite{CORANI2005513} & \checkmark &  & \checkmark & \checkmark & \checkmark & \checkmark & \checkmark &  \\
\cite{LOZOWICKA2005} &  &  & \checkmark & \checkmark &  &  & \checkmark & \checkmark \\
\cite{AGIRREBASURKO2006430} & \checkmark &  & \checkmark & \checkmark &  &  & \checkmark & \checkmark \\
\cite{VLACHOGIANNI20111559} & \checkmark &  & \checkmark &  &  &  & \checkmark & \checkmark \\
\cite{SINGH2012244} & \checkmark &  & \checkmark &  &  &  & \checkmark &  \\
\cite{Chellali2016} & \checkmark &  & \checkmark &  &  &  & \checkmark & \checkmark \\
\cite{PEREZ201622} &  &  & \checkmark &  &  &  & \checkmark &  \\
\cite{Pawul2016} & \checkmark &  &  &  &  &  & \checkmark &  \\
\cite{BIANCOFIORE2017652} & \checkmark &  & \checkmark & \checkmark &  &  & \checkmark & \checkmark \\
\cite{LUO201834} &  &  &  &  &  &  &  &  \\
\cite{LI2017997} &  &  &  &  &  &  &  &  \\
\cite{DOTSE2018358} & \checkmark &  & \checkmark &  & \checkmark &  & \checkmark & \checkmark \\
\cite{DIAZROBLES20088331} & \checkmark &  &  &  &  &  & \checkmark &  \\
\cite{CATALANO201669} & \checkmark &  &  &  &  &  & \checkmark & \checkmark \\
\cite{YEGANEH2012357} & \checkmark &  & \checkmark &  &  &  & \checkmark & \checkmark \\
\cite{SUN2017144} & \checkmark &  &  &  &  &  &  &  \\
\cite{YANG201812} & \checkmark &  & \checkmark &  & \checkmark &  & \checkmark & \checkmark \\
\cite{CHENG20112016} & \checkmark &  & \checkmark &  &  & \checkmark & \checkmark & \checkmark \\
\cite{DOMANSKA20127673} & \checkmark & \checkmark &  &  &  &  & \checkmark & \checkmark \\
\cite{GULERDINCER2018157} &  &  &  &  &  &  &  &  \\
\cite{SIWEK2016} & \checkmark &  & \checkmark &  &  & \checkmark & \checkmark &  \\
\cite{SUN201393} & \checkmark & \checkmark & \checkmark &  & \checkmark &  & \checkmark &  \\ \bottomrule
\end{tabular}
\end{table}
\end{landscape}



\begin{landscape}
\begin{table}[htp]
\centering
\small
\rowstripes
\caption{Other variables used in related work}
\label{tab:related-work-other-variables}
\begin{tabular}{p{0.3\linewidth - 2\tabcolsep-2\tabcolsep}
    |p{0.2\linewidth - 2\tabcolsep}
    |p{0.1\linewidth - 2\tabcolsep}
    |p{0.4\linewidth - 2\tabcolsep}}
\toprule
Source & Temporal variables & Traffic flow & Study-specific variables \\ \midrule
\cite{COBOURN20103015} &  &  & 24-hour $PM2.5$ back-trajectories, influence of fireworks during July 4 \\
\cite{Sotoudeheian2014} &  &  & aerosol optical depth, planetary boundary layer’s height \\
\cite{WESTERLUND201422} & month, day of the week &  & squared values of the input variables \\
\cite{GARDNER1999709} &  &  & low cloud amount, base of the lowest cloud, visibility, dry bulb temperature, vapour pressure \\
\cite{KUKKONEN2003} & day of the week, sine and cosine of the year day, hour & \checkmark & multiple variables describing the state of the atmosphere e.g.: Monin-Obukhov length, mixing height, cloudiness, visibility \\
\cite{CORANI2005513} &  &  & Pasquill stability class \\
\cite{LOZOWICKA2005} &  &  & presence of an inversion layer \\
\cite{AGIRREBASURKO2006430} &  & \checkmark & radiation, thermal gradient \\
\cite{VLACHOGIANNI20111559} &  &  & Monin-Obukhov length, mixing height \\
\cite{SINGH2012244} &  &  & respirable suspended particulate matter \\
\cite{PEREZ201622} &  &  & forecasted thermal amplitude and ventilation index \\
\cite{DOTSE2018358} & sine and cosine of the day of the week and the month of the year &  &  \\
\cite{CATALANO201669} &  & \checkmark &  \\
\cite{DOMANSKA20127673} &  &  & cloud cover, height of convection cloud, cloud cover, water vapour pressure, ground fog, forecasted values of the weather variables \\
\cite{SIWEK2016} & season, type of the day - working or weekend &  & pollution levels and humidity predicted by linear trend \\
\bottomrule
\end{tabular}
\end{table}
\end{landscape}